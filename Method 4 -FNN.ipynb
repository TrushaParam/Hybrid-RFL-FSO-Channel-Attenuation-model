{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1c1e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae1f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your synthetic dataset (replace with your data loading code)\n",
    "data = pd.read_csv('RFLFSODataFull.csv')\n",
    "# Handle categorical variable encoding\n",
    "# Perform one-hot encoding for 'SYNOP Code'\n",
    "data = pd.get_dummies(data, columns=['SYNOPCode'], prefix='SYNOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62563f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "df = scaler.fit_transform(data)\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015c87ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.303765</td>\n",
       "      <td>-2.441623</td>\n",
       "      <td>1.179803</td>\n",
       "      <td>1.087042</td>\n",
       "      <td>1.247569</td>\n",
       "      <td>-0.301459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.588342</td>\n",
       "      <td>2.554355</td>\n",
       "      <td>2.689389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.214758</td>\n",
       "      <td>-3.687910</td>\n",
       "      <td>1.174741</td>\n",
       "      <td>1.082501</td>\n",
       "      <td>1.242873</td>\n",
       "      <td>-0.301937</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.263048</td>\n",
       "      <td>2.372298</td>\n",
       "      <td>2.201101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.141870</td>\n",
       "      <td>-2.768148</td>\n",
       "      <td>1.146199</td>\n",
       "      <td>1.089977</td>\n",
       "      <td>1.097362</td>\n",
       "      <td>-0.300263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.222304</td>\n",
       "      <td>0.693283</td>\n",
       "      <td>1.270710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.118091</td>\n",
       "      <td>-3.734597</td>\n",
       "      <td>1.094568</td>\n",
       "      <td>1.029703</td>\n",
       "      <td>1.080952</td>\n",
       "      <td>-0.301711</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517924</td>\n",
       "      <td>0.671950</td>\n",
       "      <td>0.488425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.197400</td>\n",
       "      <td>-2.844550</td>\n",
       "      <td>1.093791</td>\n",
       "      <td>1.122343</td>\n",
       "      <td>1.003856</td>\n",
       "      <td>-0.300942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.426081</td>\n",
       "      <td>1.453674</td>\n",
       "      <td>1.512747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91374</th>\n",
       "      <td>0.541966</td>\n",
       "      <td>0.055350</td>\n",
       "      <td>1.805463</td>\n",
       "      <td>1.768580</td>\n",
       "      <td>1.804639</td>\n",
       "      <td>0.360877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.432857</td>\n",
       "      <td>-0.597249</td>\n",
       "      <td>-0.431970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91375</th>\n",
       "      <td>0.577360</td>\n",
       "      <td>-0.157797</td>\n",
       "      <td>1.802863</td>\n",
       "      <td>1.869034</td>\n",
       "      <td>1.670343</td>\n",
       "      <td>0.360301</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.358104</td>\n",
       "      <td>-0.448822</td>\n",
       "      <td>-0.359503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91376</th>\n",
       "      <td>0.488644</td>\n",
       "      <td>-0.180653</td>\n",
       "      <td>1.810792</td>\n",
       "      <td>1.753258</td>\n",
       "      <td>1.802199</td>\n",
       "      <td>0.359995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.381188</td>\n",
       "      <td>-0.527882</td>\n",
       "      <td>-0.380267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91377</th>\n",
       "      <td>0.616866</td>\n",
       "      <td>-0.163494</td>\n",
       "      <td>1.580807</td>\n",
       "      <td>1.505660</td>\n",
       "      <td>1.639304</td>\n",
       "      <td>0.359701</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.752055</td>\n",
       "      <td>1.730512</td>\n",
       "      <td>1.776841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005460</td>\n",
       "      <td>0.237584</td>\n",
       "      <td>-0.003246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91378</th>\n",
       "      <td>0.954152</td>\n",
       "      <td>-0.121326</td>\n",
       "      <td>1.540663</td>\n",
       "      <td>1.605559</td>\n",
       "      <td>1.529642</td>\n",
       "      <td>0.360514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.168454</td>\n",
       "      <td>3.266584</td>\n",
       "      <td>3.101356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.432857</td>\n",
       "      <td>-0.390404</td>\n",
       "      <td>-0.431970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91379 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5    6   \\\n",
       "0      0.303765 -2.441623  1.179803  1.087042  1.247569 -0.301459  0.0   \n",
       "1      0.214758 -3.687910  1.174741  1.082501  1.242873 -0.301937 -1.0   \n",
       "2      0.141870 -2.768148  1.146199  1.089977  1.097362 -0.300263  0.0   \n",
       "3      0.118091 -3.734597  1.094568  1.029703  1.080952 -0.301711 -1.0   \n",
       "4      0.197400 -2.844550  1.093791  1.122343  1.003856 -0.300942  0.0   \n",
       "...         ...       ...       ...       ...       ...       ...  ...   \n",
       "91374  0.541966  0.055350  1.805463  1.768580  1.804639  0.360877  0.0   \n",
       "91375  0.577360 -0.157797  1.802863  1.869034  1.670343  0.360301 -1.0   \n",
       "91376  0.488644 -0.180653  1.810792  1.753258  1.802199  0.359995  0.0   \n",
       "91377  0.616866 -0.163494  1.580807  1.505660  1.639304  0.359701 -1.0   \n",
       "91378  0.954152 -0.121326  1.540663  1.605559  1.529642  0.360514  0.0   \n",
       "\n",
       "             7         8         9   ...        23        24        25   26  \\\n",
       "0      0.000000  0.000000  0.000000  ...  2.588342  2.554355  2.689389  0.0   \n",
       "1      0.000000  0.000000  0.000000  ...  2.263048  2.372298  2.201101  0.0   \n",
       "2      0.000000  0.000000  0.000000  ...  1.222304  0.693283  1.270710  0.0   \n",
       "3      0.000000  0.000000  0.000000  ...  0.517924  0.671950  0.488425  0.0   \n",
       "4      0.000000  0.000000  0.000000  ...  1.426081  1.453674  1.512747  0.0   \n",
       "...         ...       ...       ...  ...       ...       ...       ...  ...   \n",
       "91374  0.000000  0.000000  0.000000  ... -0.432857 -0.597249 -0.431970  0.0   \n",
       "91375  0.000000  0.000000  0.000000  ... -0.358104 -0.448822 -0.359503  0.0   \n",
       "91376  0.000000  0.000000  0.000000  ... -0.381188 -0.527882 -0.380267  0.0   \n",
       "91377  1.752055  1.730512  1.776841  ...  0.005460  0.237584 -0.003246  0.0   \n",
       "91378  3.168454  3.266584  3.101356  ... -0.432857 -0.390404 -0.431970  0.0   \n",
       "\n",
       "        27   28   29   30   31   32  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  \n",
       "91374  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "91375  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "91376  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "91377  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "91378  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[91379 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a23bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([0, 1], axis=1).copy()  # Features (input)  0 = FSO, 1 = RFL\n",
    "y = df[[0, 1]]  # Target variables (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83607b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2fa6805",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 17:52:29.039579: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-21 17:52:29.040878: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                2048      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610,242\n",
      "Trainable params: 610,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Input layer\n",
    "    keras.layers.Input(shape=(X_train.shape[1])),  \n",
    "    # Hidden layer with ReLU activation\n",
    "    keras.layers.Dense(64, activation='relu'),   \n",
    "    keras.layers.Dense(128, activation='relu'),  \n",
    "    keras.layers.Dense(256, activation='relu'),  \n",
    "    keras.layers.Dense(512, activation='relu'),  \n",
    "    keras.layers.Dense(512, activation='relu'),  \n",
    "    keras.layers.Dense(256, activation='relu'),  \n",
    "    keras.layers.Dense(128, activation='relu'),  \n",
    "    keras.layers.Dense(64, activation='relu'), \n",
    "    # Output layer\n",
    "    keras.layers.Dense(2)   \n",
    "])\n",
    "  \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd6f4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('Adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c09bff",
   "metadata": {},
   "source": [
    "## Epochs 5 Batch Size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1378624d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 17:55:00.470615: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999/1999 [==============================] - 20s 10ms/step - loss: 0.3782\n",
      "Epoch 2/5\n",
      "1999/1999 [==============================] - 19s 9ms/step - loss: 0.2570\n",
      "Epoch 3/5\n",
      "1999/1999 [==============================] - 19s 9ms/step - loss: 0.1762\n",
      "Epoch 4/5\n",
      "1999/1999 [==============================] - 19s 10ms/step - loss: 0.1605\n",
      "Epoch 5/5\n",
      "1999/1999 [==============================] - 19s 9ms/step - loss: 0.1611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bb5068b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7daa0c0",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9acdc42e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  32/1999 [..............................] - ETA: 6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 17:56:40.002433: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999/1999 [==============================] - 6s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_5_32 = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "598a1107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with 5 epochs and 32 Batch Size:  0.3990439242701939\n",
      "R2 with 5 epochs and 32 Batch Size:  0.8751451714153524\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean squared error\n",
    "train_mse = mean_squared_error(y_train, y_pred_train_5_32)\n",
    "\n",
    "# Calculate root mean squared error  \n",
    "train_rmse_5_32 = math.sqrt(train_mse)\n",
    "print(\"RMSE with 5 epochs and 32 Batch Size: \", train_rmse_5_32)\n",
    "\n",
    "# Calculate the R-squared value\n",
    "train_r2_5_32 = r2_score(y_train, y_pred_train_5_32)\n",
    "print(\"R2 with 5 epochs and 32 Batch Size: \", train_r2_5_32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace0c12f",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d33dcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857/857 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_5_32 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08461312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with 5 epochs and 32 Batch Size:  0.399597037979844\n",
      "R2 with 5 epochs and 32 Batch Size:  0.874637104462645\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean squared error\n",
    "train_mse = mean_squared_error(y_test, y_pred_test_5_32)\n",
    "\n",
    "# Calculate root mean squared error  \n",
    "test_rmse_5_32 = math.sqrt(train_mse)\n",
    "print(\"RMSE with 5 epochs and 32 Batch Size: \", test_rmse_5_32)\n",
    "\n",
    "# Calculate the R-squared value\n",
    "test_r2_5_32 = r2_score(y_test, y_pred_test_5_32)\n",
    "print(\"R2 with 5 epochs and 32 Batch Size: \", test_r2_5_32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da07afa4",
   "metadata": {},
   "source": [
    "# Epochs 50 and batch size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0480820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6397/6397 [==============================] - 68s 10ms/step - loss: 0.2123\n",
      "Epoch 2/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1757\n",
      "Epoch 3/50\n",
      "6397/6397 [==============================] - 69s 11ms/step - loss: 0.1714\n",
      "Epoch 4/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1556\n",
      "Epoch 5/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1733\n",
      "Epoch 6/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1624\n",
      "Epoch 7/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1470\n",
      "Epoch 8/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1440\n",
      "Epoch 9/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1388\n",
      "Epoch 10/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1272\n",
      "Epoch 11/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1253\n",
      "Epoch 12/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1275\n",
      "Epoch 13/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1287\n",
      "Epoch 14/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1304\n",
      "Epoch 15/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1231\n",
      "Epoch 16/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1183\n",
      "Epoch 17/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1359\n",
      "Epoch 18/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1171\n",
      "Epoch 19/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1173\n",
      "Epoch 20/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1108\n",
      "Epoch 21/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1141\n",
      "Epoch 22/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1121\n",
      "Epoch 23/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1142\n",
      "Epoch 24/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1178\n",
      "Epoch 25/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1096\n",
      "Epoch 26/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1165\n",
      "Epoch 27/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1084\n",
      "Epoch 28/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1083\n",
      "Epoch 29/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1051\n",
      "Epoch 30/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1082\n",
      "Epoch 31/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1040\n",
      "Epoch 32/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.0994\n",
      "Epoch 33/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1041\n",
      "Epoch 34/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1035\n",
      "Epoch 35/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1078\n",
      "Epoch 36/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1111\n",
      "Epoch 37/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1177\n",
      "Epoch 38/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1080\n",
      "Epoch 39/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1036\n",
      "Epoch 40/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1006\n",
      "Epoch 41/50\n",
      "6397/6397 [==============================] - 66s 10ms/step - loss: 0.1060\n",
      "Epoch 42/50\n",
      "6397/6397 [==============================] - 65s 10ms/step - loss: 0.1038\n",
      "Epoch 43/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.0977\n",
      "Epoch 44/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1513\n",
      "Epoch 45/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1015\n",
      "Epoch 46/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1186\n",
      "Epoch 47/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.0997\n",
      "Epoch 48/50\n",
      "6397/6397 [==============================] - 63s 10ms/step - loss: 0.1084\n",
      "Epoch 49/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1033\n",
      "Epoch 50/50\n",
      "6397/6397 [==============================] - 64s 10ms/step - loss: 0.1034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x290a7d9a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9691d86",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6aead6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999/1999 [==============================] - 5s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_5_32 = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e3510fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with 5 epochs and 32 Batch Size:  0.32167315527998824\n",
      "R2 with 5 epochs and 32 Batch Size:  0.9260084267412062\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean squared error\n",
    "train_mse = mean_squared_error(y_train, y_pred_train_5_32)\n",
    "\n",
    "# Calculate root mean squared error  \n",
    "train_rmse_5_32 = math.sqrt(train_mse)\n",
    "print(\"RMSE with 5 epochs and 32 Batch Size: \", train_rmse_5_32)\n",
    "\n",
    "# Calculate the R-squared value\n",
    "train_r2_5_32 = r2_score(y_train, y_pred_train_5_32)\n",
    "print(\"R2 with 5 epochs and 32 Batch Size: \", train_r2_5_32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f523ad2",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b8586da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857/857 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_5_32 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a755b5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with 5 epochs and 32 Batch Size:  0.3179534293576756\n",
      "R2 with 5 epochs and 32 Batch Size:  0.9214137114551699\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean squared error\n",
    "train_mse = mean_squared_error(y_test, y_pred_test_5_32)\n",
    "\n",
    "# Calculate root mean squared error  \n",
    "test_rmse_5_32 = math.sqrt(train_mse)\n",
    "print(\"RMSE with 5 epochs and 32 Batch Size: \", test_rmse_5_32)\n",
    "\n",
    "# Calculate the R-squared value\n",
    "test_r2_5_32 = r2_score(y_test, y_pred_test_5_32)\n",
    "print(\"R2 with 5 epochs and 32 Batch Size: \", test_r2_5_32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459930ce",
   "metadata": {},
   "source": [
    "# Epochs 40 and batch size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b668137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.0683\n",
      "Epoch 2/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0618\n",
      "Epoch 3/40\n",
      "125/125 [==============================] - 2s 13ms/step - loss: 0.0580\n",
      "Epoch 4/40\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.0556\n",
      "Epoch 5/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0539\n",
      "Epoch 6/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0532\n",
      "Epoch 7/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0513\n",
      "Epoch 8/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0505\n",
      "Epoch 9/40\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.0501\n",
      "Epoch 10/40\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.0490\n",
      "Epoch 11/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0485\n",
      "Epoch 12/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0480\n",
      "Epoch 13/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0475\n",
      "Epoch 14/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0493\n",
      "Epoch 15/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0466\n",
      "Epoch 16/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0452\n",
      "Epoch 17/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0478\n",
      "Epoch 18/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0472\n",
      "Epoch 19/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0449\n",
      "Epoch 20/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0433\n",
      "Epoch 21/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0437\n",
      "Epoch 22/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0419\n",
      "Epoch 23/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0404\n",
      "Epoch 24/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0403\n",
      "Epoch 25/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0431\n",
      "Epoch 26/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0427\n",
      "Epoch 27/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0406\n",
      "Epoch 28/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0389\n",
      "Epoch 29/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0435\n",
      "Epoch 30/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0434\n",
      "Epoch 31/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0402\n",
      "Epoch 32/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0403\n",
      "Epoch 33/40\n",
      "125/125 [==============================] - 2s 12ms/step - loss: 0.0443\n",
      "Epoch 34/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0426\n",
      "Epoch 35/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0411\n",
      "Epoch 36/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0382\n",
      "Epoch 37/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0375\n",
      "Epoch 38/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0364\n",
      "Epoch 39/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0366\n",
      "Epoch 40/40\n",
      "125/125 [==============================] - 1s 12ms/step - loss: 0.0445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29bc1cd00>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=40, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98705aad",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b5be4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999/1999 [==============================] - 6s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_40_512 = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50569389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with 5 epochs and 32 Batch Size:  0.20172020292069295\n",
      "R2 with 5 epochs and 32 Batch Size:  0.9629685125994563\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean squared error\n",
    "train_mse = mean_squared_error(y_train, y_pred_train_40_512)\n",
    "\n",
    "# Calculate root mean squared error  \n",
    "train_rmse_40_512 = math.sqrt(train_mse)\n",
    "print(\"RMSE with 5 epochs and 32 Batch Size: \", train_rmse_40_512)\n",
    "\n",
    "# Calculate the R-squared value\n",
    "train_r2_40_512 = r2_score(y_train, y_pred_train_40_512)\n",
    "print(\"R2 with 5 epochs and 32 Batch Size: \", train_r2_40_512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ad13ec",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cec0437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857/857 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_40_512 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "778efbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with 5 epochs and 32 Batch Size:  0.24693151855298381\n",
      "R2 with 5 epochs and 32 Batch Size:  0.9484239609631342\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean squared error\n",
    "train_mse = mean_squared_error(y_test, y_pred_test_40_512)\n",
    "\n",
    "# Calculate root mean squared error  \n",
    "test_rmse_40_512 = math.sqrt(train_mse)\n",
    "print(\"RMSE with 5 epochs and 32 Batch Size: \", test_rmse_40_512)\n",
    "\n",
    "# Calculate the R-squared value\n",
    "test_r2_40_512 = r2_score(y_test, y_pred_test_40_512)\n",
    "print(\"R2 with 5 epochs and 32 Batch Size: \", test_r2_40_512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2b086e",
   "metadata": {},
   "source": [
    "# Pearson Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ae82e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data = {\n",
    "# #     'RFL_Att': rfl_train_predictions,\n",
    "# #     'FSO_Att': fso_train_predictions\n",
    "# # }\n",
    "\n",
    "# df_train = pd.DataFrame(train_y_pred)\n",
    "\n",
    "# # Calculate the Pearson correlation coefficient\n",
    "# correlation = df_train[0].corr(df_train[1])\n",
    "\n",
    "# print(\"Pearson Correlation Coefficient:\")\n",
    "# print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f67d8996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient:\n",
      "0.12355248460702419\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame(y_pred_train_40_512)\n",
    "\n",
    "# Calculate the Pearson correlation coefficient\n",
    "correlation = df_train[0].corr(df_train[1])\n",
    "\n",
    "print(\"Pearson Correlation Coefficient:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6fc864c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient:\n",
      "0.12402675034439381\n"
     ]
    }
   ],
   "source": [
    "# data = {\n",
    "#     'RFL_Att': rfl_train_predictions,\n",
    "#     'FSO_Att': fso_train_predictions\n",
    "# }\n",
    "\n",
    "df_test = pd.DataFrame(y_pred_test_40_512)\n",
    "\n",
    "# Calculate the Pearson correlation coefficient\n",
    "correlation = df_test[0].corr(df_test[1])\n",
    "\n",
    "print(\"Pearson Correlation Coefficient:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b624d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test\n",
    "# Calculate the Pearson correlation coefficient\n",
    "correlation = y_test[0].corr(y_test[1])\n",
    "\n",
    "print(\"Pearson Correlation Coefficient:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae667e98",
   "metadata": {},
   "source": [
    "# Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a1265d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.062233596857219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trushaparam/miniforge3/lib/python3.9/site-packages/sklearn/metrics/cluster/_supervised.py:64: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and continuous values for target\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# Calculate mutual information for training\n",
    "mutual_information = mutual_info_score(df_train[0], df_train[1])\n",
    "print(mutual_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20eb169f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.217494320779322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trushaparam/miniforge3/lib/python3.9/site-packages/sklearn/metrics/cluster/_supervised.py:64: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and continuous values for target\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# Calculate mutual information for training\n",
    "mutual_information = mutual_info_score(df_test[0], df_test[1])\n",
    "print(mutual_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a9b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
